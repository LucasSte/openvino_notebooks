{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation demo\n",
    "This demo utilizes Intel's pre-trained model that translates from English to German. More information about the model can be found [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/machine-translation-nar-en-de-0002/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading model\n",
    "The following command will download the model to the current directory. Please, make sure you have run `pip install openvino-dev` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading machine-translation-nar-en-de-0002 ||################\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_tgt/merges.txt\n",
      "... 100%, 330 KB, 419 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_tgt/vocab.json\n",
      "... 100%, 543 KB, 766 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_src/merges.txt\n",
      "... 100%, 311 KB, 468 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_src/vocab.json\n",
      "... 100%, 523 KB, 566 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.xml\n",
      "... 100%, 982 KB, 1020 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.bin\n",
      "... 100%, 277878 KB, 21316 KB/s, 13 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP16/machine-translation-nar-en-de-0002.xml\n",
      "... 100%, 1149 KB, 1063 KB/s, 1 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP16/machine-translation-nar-en-de-0002.bin\n",
      "... 100%, 138939 KB, 16071 KB/s, 8 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --name  machine-translation-nar-en-de-0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tokenizers import SentencePieceBPETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and configuring the model\n",
    "The model we use here is available under the `intel/` folder, so we load it and configure its inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "core = Core()\n",
    "model = core.read_model('intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.xml')\n",
    "compiled_model = core.compile_model(model)\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_name = \"tokens\"\n",
    "output_name = \"pred\"\n",
    "model.output(output_name)\n",
    "max_tokens = model.input(input_name).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading tokenizers\n",
    "Before we feed our models with an input sentence, it needs to be transformed into tokens it understands. Likewise, we must transform the output into a sentence we can read.\n",
    "\n",
    "We initialize here the tokenizer for the input `src_tokenizer` and the tokenizer for the output `tgt_tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_src/vocab.json',\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_src/merges.txt'\n",
    ")\n",
    "tgt_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_tgt/vocab.json',\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_tgt/merges.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Performing translation\n",
    "The following function received a sentence in English and translates it to German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # Removes leading and trailing whitespaces\n",
    "    sentence = sentence.strip()\n",
    "    assert len(sentence) > 0\n",
    "    tokens = src_tokenizer.encode(sentence).ids\n",
    "    # Here we transform the tokenized sentence into the model's input format\n",
    "    tokens = [src_tokenizer.token_to_id('<s>')] + tokens + [src_tokenizer.token_to_id('</s>')]\n",
    "    pad_length = max_tokens - len(tokens)\n",
    "\n",
    "    # If the sentence size is smaller the maximum allowed tokens, we fill the remaining tokens with '<pad>'.\n",
    "    if pad_length > 0:\n",
    "        tokens = tokens + [src_tokenizer.token_to_id('<pad>')]*pad_length\n",
    "    assert len(tokens) == max_tokens, \"input sentence is too long\"\n",
    "    encoded_sentence = np.array(tokens).reshape(1, -1)\n",
    "\n",
    "    # Perform inference\n",
    "    infer_request.infer({input_name: encoded_sentence})\n",
    "    enc_translated = infer_request.get_tensor(output_name).data[:]\n",
    "\n",
    "    # Decode the sentence\n",
    "    sentence = tgt_tokenizer.decode(enc_translated[0])\n",
    "\n",
    "    # Remove <pad> tokens, as well as '<s>' and '</s>' tokens which mark the beginning and ending of the sentence.\n",
    "    for s in ['</s>', '<s>', '<pad>']:\n",
    "        sentence = sentence.replace(s, '')\n",
    "\n",
    "    # Transform sentence into lower case and join words by a white space\n",
    "    sentence = sentence.lower().split()\n",
    "    sentence = \" \".join(key for key, _ in itertools.groupby(sentence))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating sentence\n",
    "The following function is a basic loop to keep translating sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_translator():\n",
    "    while True:\n",
    "        input_sentence = input()\n",
    "        if input_sentence == \"\":\n",
    "            break\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        translated = translate(input_sentence)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f'Translated: {translated}')\n",
    "        print(f'Time: {end_time - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is rainning now.\n",
      "Translated: es regnetnet jetzt jetzt.\n",
      "Time: 0.34s\n",
      "The weather is good\n",
      "Translated: das wetter ist gut.\n",
      "Time: 0.20s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mrun_translator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_translator\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         input_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m input_sentence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opvn/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opvn/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "run_translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
