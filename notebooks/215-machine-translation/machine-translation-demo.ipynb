{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine translation demo\n",
    "This demo utilizes Intel's pre-trained model that translates from English to German. More information about the model can be found [here](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/machine-translation-nar-en-de-0002/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading model\n",
    "The following command will download the model to the current directory. Please, make sure you have run `pip install openvino-dev` beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading machine-translation-nar-en-de-0002 ||################\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_tgt/merges.txt\n",
      "... 100%, 330 KB, 468 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_tgt/vocab.json\n",
      "... 100%, 543 KB, 597 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_src/merges.txt\n",
      "... 100%, 311 KB, 2128 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/tokenizer_src/vocab.json\n",
      "... 100%, 523 KB, 2356 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.xml\n",
      "... 100%, 982 KB, 1135 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.bin\n",
      "... 100%, 277878 KB, 21126 KB/s, 13 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP16/machine-translation-nar-en-de-0002.xml\n",
      "... 100%, 1149 KB, 1181 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading /home/lucas/Documents/openvino_notebooks/notebooks/215-machine-translation/intel/machine-translation-nar-en-de-0002/FP16/machine-translation-nar-en-de-0002.bin\n",
      "... 100%, 138939 KB, 17708 KB/s, 7 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --name  machine-translation-nar-en-de-0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from openvino.runtime import Core\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tokenizers import SentencePieceBPETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load and configure the model\n",
    "The model is now available in the `intel/` folder. Below we load and configure its inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "core = Core()\n",
    "model = core.read_model('intel/machine-translation-nar-en-de-0002/FP32/machine-translation-nar-en-de-0002.xml')\n",
    "compiled_model = core.compile_model(model)\n",
    "infer_request = compiled_model.create_infer_request()\n",
    "input_name = \"tokens\"\n",
    "output_name = \"pred\"\n",
    "model.output(output_name)\n",
    "max_tokens = model.input(input_name).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading tokenizers\n",
    "Before we feed our models with an input sentence, it needs to be transformed into tokens it understands. Likewise, we must transform the output into a sentence we can read.\n",
    "\n",
    "We initialize here the tokenizer for the input `src_tokenizer` and the tokenizer for the output `tgt_tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_src/vocab.json',\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_src/merges.txt'\n",
    ")\n",
    "tgt_tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_tgt/vocab.json',\n",
    "    'intel/machine-translation-nar-en-de-0002/tokenizer_tgt/merges.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Performing translation\n",
    "The following function received a sentence in English and translates it to German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # Removes leading and trailing whitespaces\n",
    "    sentence = sentence.strip()\n",
    "    assert len(sentence) > 0\n",
    "    tokens = src_tokenizer.encode(sentence).ids\n",
    "    # Here we transform the tokenized sentence into the model's input format\n",
    "    tokens = [src_tokenizer.token_to_id('<s>')] + tokens + [src_tokenizer.token_to_id('</s>')]\n",
    "    pad_length = max_tokens - len(tokens)\n",
    "\n",
    "    # If the sentence size is less than the maximum allowed tokens, fill the remaining tokens with '<pad>'.\n",
    "    if pad_length > 0:\n",
    "        tokens = tokens + [src_tokenizer.token_to_id('<pad>')] * pad_length\n",
    "    assert len(tokens) == max_tokens, \"input sentence is too long\"\n",
    "    encoded_sentence = np.array(tokens).reshape(1, -1)\n",
    "\n",
    "    # Perform inference\n",
    "    infer_request.infer({input_name: encoded_sentence})\n",
    "    enc_translated = infer_request.get_tensor(output_name).data[:]\n",
    "\n",
    "    # Decode the sentence\n",
    "    sentence = tgt_tokenizer.decode(enc_translated[0])\n",
    "\n",
    "    # Remove <pad> tokens, as well as '<s>' and '</s>' tokens which mark the beginning and ending of the sentence.\n",
    "    for s in ['</s>', '<s>', '<pad>']:\n",
    "        sentence = sentence.replace(s, '')\n",
    "\n",
    "    # Transform sentence into lower case and join words by a white space\n",
    "    sentence = sentence.lower().split()\n",
    "    sentence = \" \".join(key for key, _ in itertools.groupby(sentence))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the sentence\n",
    "The following function is a basic loop that translates sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_translator():\n",
    "    while True:\n",
    "        input_sentence = input()\n",
    "        if input_sentence == \"\":\n",
    "            break\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        translated = translate(input_sentence)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f'Translated: {translated}')\n",
    "        print(f'Time: {end_time - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_translator() # uncomment this line for a real time translation of your input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your translation\n",
    "Run the following cell with an English sentence to have it translated to German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: mein name ist openvino.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My name is openvino\"\n",
    "print(f'Translated: {translate(sentence)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
